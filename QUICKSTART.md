# –ö—Ä–∞—Ç–∫–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ - Dataset Crawler

## ‚ö° –°–∞–º—ã–µ –±—ã—Å—Ç—Ä—ã–µ –ø—Ä–∏–º–µ—Ä—ã

### –û–¥–∏–Ω–æ—á–Ω—ã–π URL
```bash
cd build
./crawler --url "https://example.com"
```

### –ù–µ—Å–∫–æ–ª—å–∫–æ URL
```bash
./crawler --urls "https://site1.com,https://site2.com,https://site3.com"
```

### –° –∫–∞—Å—Ç–æ–º–Ω—ã–º User-Agent
```bash
./crawler --url "https://mysite.com" --user-agent "MyBot/1.0"
```

### –° –∫–æ–Ω—Ñ–∏–≥ —Ñ–∞–π–ª–æ–º
```bash
./crawler --config ../config.json
```

### –° —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º timeout
```bash
./crawler --url "https://mysite.com" --timeout 60
```

## ‚ö†Ô∏è LinkedIn - –°–¢–†–û–ì–û –ó–ê–ü–†–ï–©–ï–ù–û!

```bash
# ‚ùå –ù–ï –î–ï–õ–ê–ô –≠–¢–û!
./crawler --url "https://linkedin.com"
```

LinkedIn **—è–≤–Ω–æ –∑–∞–ø—Ä–µ—â–∞–µ—Ç** –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫—Ä–∞—É–ª–∏–Ω–≥ –≤ —Å–≤–æ–∏—Ö Terms of Service. –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫:
- üö´ –ë–ª–æ–∫–∏—Ä–æ–≤–∫–µ –∞–∫–∫–∞—É–Ω—Ç–∞
- ‚öñÔ∏è –°—É–¥–µ–±–Ω—ã–º –∏—Å–∫–∞–º
- üí∞ –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–º —à—Ç—Ä–∞—Ñ–∞–º

**–ó–∞–∫–æ–Ω–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã:**
1. LinkedIn API - –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–±
2. LinkedIn Data Scrape - –ø–ª–∞—Ç–Ω—ã–π —Å–µ—Ä–≤–∏—Å
3. –†—É—á–Ω–æ–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
4. –ü—É–±–ª–∏—á–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (LinkedIn Research, Kaggle)

## üìö –†–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã

### Wikipedia (‚úÖ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ)
```bash
./crawler --urls "https://en.wikipedia.org/wiki/Machine_learning,https://en.wikipedia.org/wiki/Artificial_intelligence"
```

### GitHub (‚úÖ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ)
make build
```

–ò–ª–∏ –ø–æ—à–∞–≥–æ–≤–æ:
```bash
mkdir -p build
cd build
cmake ..
make
cd ..
```

### 3. –ó–∞–ø—É—Å–∫ –∫—Ä–∞—É–ª–µ—Ä–∞

```bash
make run
```

–ò–ª–∏ –Ω–∞–ø—Ä—è–º—É—é:
```bash
./build/crawler
```

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –ü—Ä–æ—Å—Ç–æ–π –∫—Ä–∞—É–ª–∏–Ω–≥

```cpp
#include "crawler.h"
#include "dataset_writer.h"

int main() {
    WebCrawler crawler;
    DataRecord record = crawler.fetch("https://example.com");
    
    ParquetDatasetWriter writer;
    std::vector<DataRecord> records = {record};
    writer.write_records("data.parquet", records);
    
    return 0;
}
```

### –ü—Ä–∏–º–µ—Ä 2: –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π –∫—Ä–∞—É–ª–∏–Ω–≥

```cpp
#include "advanced_crawler.h"

int main() {
    AdvancedCrawler crawler(8);  // 8 –ø–æ—Ç–æ–∫–æ–≤
    
    std::vector<std::string> urls = {
        "https://example.com/1",
        "https://example.com/2",
        "https://example.com/3"
    };
    
    auto records = crawler.crawl_parallel(urls);
    
    ParquetDatasetWriter writer;
    writer.write_records("dataset.parquet", records);
    
    return 0;
}
```

### –ü—Ä–∏–º–µ—Ä 3: –ö—Ä–∞—É–ª–∏–Ω–≥ –∏–∑ —Ñ–∞–π–ª–∞

```cpp
#include "advanced_crawler.h"

int main() {
    AdvancedCrawler crawler(4);
    auto records = crawler.crawl_from_file("urls.txt");
    
    // –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    ParquetDatasetWriter writer;
    writer.write_records("output.parquet", records);
    
    return 0;
}
```

## –†–∞–±–æ—Ç–∞ —Å Parquet —Ñ–∞–π–ª–∞–º–∏

### Python - –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

```python
import pandas as pd

# –ü—Ä–æ—á–∏—Ç–∞—Ç—å Parquet —Ñ–∞–π–ª
df = pd.read_parquet('dataset.parquet')

# –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
print(df.info())
print(df.head())

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
print(df['status_code'].value_counts())
```

### Python - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —É—Ç–∏–ª–∏—Ç

```bash
# –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
python3 scripts/parquet_utils.py info dataset.parquet

# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ CSV
python3 scripts/parquet_utils.py to-csv dataset.parquet dataset.csv

# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ JSON
python3 scripts/parquet_utils.py to-json dataset.parquet dataset.json

# –°–ª–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤
python3 scripts/parquet_utils.py merge part1.parquet part2.parquet -o merged.parquet

# –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ —Å—Ç–∞—Ç—É—Å –∫–æ–¥—É
python3 scripts/parquet_utils.py filter dataset.parquet 200 -o success.parquet

# –í–∑—è—Ç—å –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö
python3 scripts/parquet_utils.py sample dataset.parquet 100 -o sample.parquet
```

## Docker –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –°–±–æ—Ä–∫–∞ –æ–±—Ä–∞–∑–∞

```bash
make docker-build
```

### –ó–∞–ø—É—Å–∫ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ

```bash
make docker-run
```

### –ü–æ–ª–Ω—ã–π Docker Compose

```bash
docker-compose up
```

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
dataset/
‚îú‚îÄ‚îÄ CMakeLists.txt              # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–±–æ—Ä–∫–∏
‚îú‚îÄ‚îÄ Makefile                    # –£–¥–æ–±–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã —Å–±–æ—Ä–∫–∏
‚îú‚îÄ‚îÄ Dockerfile                  # Docker –æ–±—Ä–∞–∑
‚îú‚îÄ‚îÄ docker-compose.yml          # Docker Compose –∫–æ–Ω—Ñ–∏–≥
‚îú‚îÄ‚îÄ requirements.txt            # Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ config.json                 # –ö–æ–Ω—Ñ–∏–≥ –∫—Ä–∞—É–ª–µ—Ä–∞
‚îú‚îÄ‚îÄ urls.txt                    # –ü—Ä–∏–º–µ—Ä URL-–æ–≤
‚îÇ
‚îú‚îÄ‚îÄ include/
‚îÇ   ‚îú‚îÄ‚îÄ crawler.h               # –ë–∞–∑–æ–≤—ã–π –∫—Ä–∞—É–ª–µ—Ä
‚îÇ   ‚îú‚îÄ‚îÄ dataset_writer.h        # –ó–∞–ø–∏—Å—å –≤ Parquet/CSV
‚îÇ   ‚îî‚îÄ‚îÄ advanced_crawler.h      # –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π –∫—Ä–∞—É–ª–µ—Ä
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.cpp                # –ì–ª–∞–≤–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞
‚îÇ   ‚îú‚îÄ‚îÄ crawler.cpp             # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫—Ä–∞—É–ª–µ—Ä–∞
‚îÇ   ‚îú‚îÄ‚îÄ dataset_writer.cpp      # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Parquet
‚îÇ   ‚îî‚îÄ‚îÄ advanced_crawler.cpp    # –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å
‚îÇ
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îî‚îÄ‚îÄ examples.cpp            # –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ parquet_utils.py        # Python —É—Ç–∏–ª–∏—Ç—ã
‚îÇ
‚îî‚îÄ‚îÄ README.md                   # –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

## –û—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã

### WebCrawler

```cpp
class WebCrawler {
    // –ü–æ–ª—É—á–∏—Ç—å –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É
    DataRecord fetch(const std::string& url);
    
    // –ö—Ä–∞—É–ª–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü
    std::vector<DataRecord> crawl_urls(const std::vector<std::string>& urls);
    
    // –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–∞–π–º–∞—É—Ç
    void set_timeout(long seconds);
    
    // –î–æ–±–∞–≤–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫
    void add_header(const std::string& key, const std::string& value);
};
```

### AdvancedCrawler

```cpp
class AdvancedCrawler {
    // –ö—Ä–∞—É–ª–∏—Ç—å —Å –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å—é
    std::vector<DataRecord> crawl_parallel(const std::vector<std::string>& urls);
    
    // –ö—Ä–∞—É–ª–∏—Ç—å –∏–∑ —Ñ–∞–π–ª–∞
    std::vector<DataRecord> crawl_from_file(const std::string& filename);
    
    // –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    Stats get_stats() const;
};
```

### ParquetDatasetWriter

```cpp
class ParquetDatasetWriter {
    // –ó–∞–ø–∏—Å–∞—Ç—å –≤ Parquet
    void write_records(const std::string& filepath, 
                      const std::vector<DataRecord>& records);
    
    // –î–æ–±–∞–≤–∏—Ç—å –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É —Ñ–∞–π–ª—É
    void append_records(const std::string& filepath,
                       const std::vector<DataRecord>& records);
    
    // –ó–∞–ø–∏—Å–∞—Ç—å –≤ CSV
    void write_csv(const std::string& filepath,
                  const std::vector<DataRecord>& records);
};
```

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

```cpp
struct DataRecord {
    std::string url;        // URL –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    std::string title;      // –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    std::string content;    // HTML –∫–æ–Ω—Ç–µ–Ω—Ç
    std::string timestamp;  // –í—Ä–µ–º—è —Å–±–æ—Ä–∞
    int status_code;        // HTTP —Å—Ç–∞—Ç—É—Å
};
```

## –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –û—à–∏–±–∫–∞: libcurl –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
```bash
sudo apt-get install libcurl4-openssl-dev
```

### –û—à–∏–±–∫–∞: Parquet –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
```bash
sudo apt-get install libparquet-dev libparquet0
```

### –û—à–∏–±–∫–∞: CMake –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
```bash
sudo apt-get install cmake
```

### –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ç—å—é
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
- –£–≤–µ–ª–∏—á—å—Ç–µ —Ç–∞–π–º–∞—É—Ç: `crawler.set_timeout(60)`
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ

## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### 1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å
```cpp
AdvancedCrawler crawler(8);  // 8 –ø–æ—Ç–æ–∫–æ–≤
auto records = crawler.crawl_parallel(urls);
```

### 2. –ë–∞—Ç—á-–∑–∞–ø–∏—Å—å
```cpp
std::vector<DataRecord> batch;
for (const auto& record : records) {
    batch.push_back(record);
    if (batch.size() >= 1000) {
        writer.write_records("part.parquet", batch);
        batch.clear();
    }
}
```

### 3. –°–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö
- Parquet –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ–º–ø—Ä–µ—Å—Å–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ
- –°–Ω–∏–∂–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ 5-10 —Ä–∞–∑

### 4. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ —Ñ–∞–π–ª–∞–º
```bash
python3 scripts/parquet_utils.py merge part*.parquet -o final.parquet
```

## –ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–∞–Ω–¥

```bash
# –°–±–æ—Ä–∫–∞ –∏ –∑–∞–ø—É—Å–∫
make clean build run

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–∞–∫ —Å–∏—Å—Ç–µ–º–Ω—É—é –∫–æ–º–∞–Ω–¥—É
make install

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Docker
docker build -t crawler .
docker run -v $(pwd):/app crawler

# –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
python3 -c "import pandas; df=pandas.read_parquet('dataset.parquet'); print(df.info())"
```

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Apache Arrow documentation](https://arrow.apache.org/)
- [Parquet format](https://parquet.apache.org/)
- [libcurl documentation](https://curl.se/libcurl/)
- [CMake documentation](https://cmake.org/documentation/)

## –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License - –°–≤–æ–±–æ–¥–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –ª–∏—á–Ω—ã—Ö –∏ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö —Ü–µ–ª—è—Ö.
