# üöÄ Dataset Crawler - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫—Ä–∞—É–ª–µ—Ä–∞ –Ω–∞ —Å–≤–æ–π —Å–∞–π—Ç

### 1Ô∏è‚É£ –°–ø–æ—Å–æ–± ‚Ññ1: Command-line –∞—Ä–≥—É–º–µ–Ω—Ç—ã (—Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π)

```bash
cd build
./crawler --url "https://yoursite.com"
```

**–ü—Ä–∏–º–µ—Ä—ã:**

```bash
# –û–¥–∏–Ω URL
./crawler --url "https://example.com"

# –ù–µ—Å–∫–æ–ª—å–∫–æ URL (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
./crawler --urls "https://site1.com,https://site2.com,https://site3.com"

# –° –∫–∞—Å—Ç–æ–º–Ω—ã–º User-Agent
./crawler --url "https://mysite.com" --user-agent "MyBot/1.0"

# –° —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º timeout (–¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–∞–π—Ç–æ–≤)
./crawler --url "https://mysite.com" --timeout 60

# –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–º–µ—Å—Ç–µ
./crawler --urls "https://site1.com,https://site2.com" --timeout 45 --user-agent "MyBot/1.0"
```

### 2Ô∏è‚É£ –°–ø–æ—Å–æ–± ‚Ññ2: –ö–æ–Ω—Ñ–∏–≥ —Ñ–∞–π–ª (–¥–ª—è –±–æ–ª—å—à–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤)

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π `config.json`:

```json
{
    "crawler": {
        "timeout": 30,
        "max_retries": 3,
        "user_agent": "MyBot/1.0 (+https://yoursite.com/bot)",
        "follow_redirects": true,
        "respect_robots_txt": true,
        "respect_meta_tags": true
    },
    "output": {
        "format": "both",
        "output_dir": "./output",
        "batch_size": 1000
    },
    "urls": [
        "https://example.com",
        "https://example.com/page1",
        "https://example.com/page2",
        "https://yoursite.com"
    ],
    "headers": {
        "Accept-Language": "en-US,en;q=0.9",
        "Accept-Encoding": "gzip, deflate",
        "Cache-Control": "no-cache"
    }
}
```

–ó–∞—Ç–µ–º –∑–∞–ø—É—Å—Ç–∏:
```bash
cd build
./crawler --config ../config.json
```

### 3Ô∏è‚É£ –°–ø–æ—Å–æ–± ‚Ññ3: –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã

```bash
# –ó–∞–ø—É—Å—Ç–∏ —Å–∫—Ä–∏–ø—Ç —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏
bash examples.sh 1     # Single URL
bash examples.sh 2     # Multiple URLs
bash examples.sh 3     # Wikipedia (education)
bash examples.sh 4     # GitHub Trending
bash examples.sh 5     # ArXiv (research papers)
bash examples.sh 6     # Custom User-Agent
bash examples.sh 7     # Increased timeout
bash examples.sh 8     # Config file
```

## üìã –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–º–∞–Ω–¥—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä |
|----------|---------|--------|
| `--url` | –û–¥–∏–Ω–æ—á–Ω—ã–π URL –¥–ª—è –∫—Ä–∞—É–ª–∏–Ω–≥–∞ | `--url "https://example.com"` |
| `--urls` | –ù–µ—Å–∫–æ–ª—å–∫–æ URL (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é) | `--urls "url1,url2,url3"` |
| `--timeout` | Timeout –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30) | `--timeout 60` |
| `--user-agent` | –ö–∞—Å—Ç–æ–º–Ω—ã–π User-Agent –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ | `--user-agent "MyBot/1.0"` |
| `--config` | –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥ —Ñ–∞–π–ª—É | `--config config.json` |
| `--output-dir` | –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ | `--output-dir ./data` |

## üè¢ –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å–∞–π—Ç–æ–≤

### ‚úÖ –†–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ —Å–∞–π—Ç—ã

#### Wikipedia
```bash
./crawler --urls "https://en.wikipedia.org/wiki/Machine_learning,https://en.wikipedia.org/wiki/Artificial_intelligence"
```

#### GitHub
```bash
./crawler --url "https://github.com/trending" --timeout 30
```

#### ArXiv (–Ω–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏)
```bash
./crawler --url "https://arxiv.org/list/cs.AI/recent" --timeout 20
```

#### Stack Overflow
```bash
./crawler --url "https://stackoverflow.com/questions/tagged/python" --timeout 25
```

#### Medium
```bash
./crawler --url "https://medium.com/tag/artificial-intelligence" --timeout 30
```

### ‚ùå –ó–ê–ü–†–ï–©–ï–ù–ù–´–ï —Å–∞–π—Ç—ã

#### LinkedIn - –°–¢–†–û–ì–û –ó–ê–ü–†–ï–©–ï–ù–û ‚õî
```bash
# –ù–ï –î–ï–õ–ê–ô –≠–¢–û!
./crawler --url "https://linkedin.com"
```

**–ü–æ—á–µ–º—É?** LinkedIn —è–≤–Ω–æ –∑–∞–ø—Ä–µ—â–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫—Ä–∞—É–ª–∏–Ω–≥ –≤ —Å–≤–æ–∏—Ö Terms of Service. –ù–∞—Ä—É—à–µ–Ω–∏–µ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫:
- üö´ –ë–ª–æ–∫–∏—Ä–æ–≤–∫–µ –∞–∫–∫–∞—É–Ω—Ç–∞
- ‚öñÔ∏è –°—É–¥–µ–±–Ω—ã–º –∏—Å–∫–∞–º
- üí∞ –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–º —à—Ç—Ä–∞—Ñ–∞–º (–æ—Ç $5,000 –¥–æ $100,000+ –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ CFAA)

**–õ–µ–≥–∞–ª—å–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –¥–ª—è LinkedIn:**
1. **LinkedIn API** - https://developers.linkedin.com/
2. **LinkedIn Data Download** - –ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ LinkedIn –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
3. **Kaggle Datasets** - –≥–æ—Ç–æ–≤—ã–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å LinkedIn
4. **LinkedIn Research** - –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è LinkedIn

## üìä –í—ã—Ö–æ–¥

–ö—Ä–∞—É–ª–µ—Ä —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª—ã –≤ `output/` –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:

### dataset.json
```json
[
  {
    "url": "https://example.com",
    "title": "Example Domain",
    "content_length": 1256,
    "timestamp": "2026-01-25 08:15:46",
    "status_code": 200
  }
]
```

### dataset.csv
```
url,title,content_length,timestamp,status_code
https://example.com,"Example Domain",1256,"2026-01-25 08:15:46",200
```

## üîç –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

–ö—Ä–∞—É–ª–µ—Ä –≤—ã–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏:

```
2026-01-25T08:15:46.382Z INFO   Configuration: 2 URLs, timeout: 15s
2026-01-25T08:15:46.383Z INFO   Starting the crawler.
2026-01-25T08:15:46.433Z INFO   https://example.com [200]
2026-01-25T08:15:46.480Z INFO   Crawling completed. Fetched: 2 records
```

–¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞:
- üü¢ **INFO** (–∑–µ–ª—ë–Ω—ã–π) - –£—Å–ø–µ—à–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
- üü° **WARN** (–∂—ë–ª—Ç—ã–π) - –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
- üî¥ **ERROR** (–∫—Ä–∞—Å–Ω—ã–π) - –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
- üîµ **DEBUG** (–≥–æ–ª—É–±–æ–π) - –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

## ‚öôÔ∏è –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

### –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å–∞–π—Ç–æ–≤
```bash
./crawler --url "https://mysite.com" --timeout 15
```

### –î–ª—è –±–æ–ª—å—à–∏—Ö —Å–∞–π—Ç–æ–≤
```bash
./crawler --url "https://bigsite.com" --timeout 60
```

### –î–ª—è –º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
```bash
./crawler --url "https://site.com" --timeout 90
```

### –î–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ URL
```bash
./crawler --urls "url1,url2,url3,url4,url5" --timeout 30
```

## ‚úÖ –≠—Ç–∏—á–Ω—ã–π –∫—Ä–∞—É–ª–∏–Ω–≥

–ö—Ä–∞—É–ª–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–±–ª—é–¥–∞–µ—Ç:
- ‚úÖ **robots.txt** - –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø–∞—Ä—Å–∏—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–º–µ–Ω–∞
- ‚úÖ **Meta-tags** - –ø—Ä–æ–≤–µ—Ä—è–µ—Ç `<meta name="robots" content="noindex">` 
- ‚úÖ **User-Agent** - –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–∞–π—Ç–∞–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–±—è
- ‚úÖ **Timeout** - –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞–µ—Ç —Å–µ—Ä–≤–µ—Ä

–ü–µ—Ä–µ–¥ –∫—Ä–∞—É–ª–∏–Ω–≥–æ–º —Å–∞–π—Ç–∞:
1. –ü–æ—Å–µ—Ç–∏—Ç–µ `https://yoursite.com/robots.txt`
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —Ä–∞–∑—Ä–µ—à–µ–Ω –ª–∏ –∫—Ä–∞—É–ª–∏–Ω–≥ –¥–ª—è User-Agent: `*`
3. –°–æ–±–ª—é–¥–∞–π—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å

## üîß Troubleshooting

| –ü—Ä–æ–±–ª–µ–º–∞ | –†–µ—à–µ–Ω–∏–µ |
|----------|---------|
| "Failed to open JSON file" | `mkdir -p build/output` |
| –°–∞–π—Ç –±–ª–æ–∫–∏—Ä—É–µ—Ç –∫—Ä–∞—É–ª–µ—Ä | –£–≤–µ–ª–∏—á—å timeout: `--timeout 90` |
| –°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ | –ü—Ä–æ–≤–µ—Ä—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ |
| robots.txt –±–ª–æ–∫–∏—Ä—É–µ—Ç | –≠—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ! –°–æ–±–ª—é–¥–∞–π —ç—Ç–∏ –ø—Ä–∞–≤–∏–ª–∞ |
| 403/429 —Å—Ç–∞—Ç—É—Å –∫–æ–¥ | –°–∞–π—Ç –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø (—ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ) |

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- [USAGE.md](./USAGE.md) - –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
- [LOGGING.md](./LOGGING.md) - –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—é
- [ETHICS.md](./ETHICS.md) - –≠—Ç–∏—á–Ω—ã–π –∫—Ä–∞—É–ª–∏–Ω–≥ –∏ robots.txt
- [README.md](./README.md) - API –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

## üöÄ –ü—Ä–∏–º–µ—Ä—ã —Å–∫—Ä–∏–ø—Ç–æ–≤

### –ö—Ä–∞—É–ª–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å–∞–π—Ç–æ–≤ –≤ —Ü–∏–∫–ª–µ
```bash
#!/bin/bash
for site in "https://site1.com" "https://site2.com" "https://site3.com"; do
    ./crawler --url "$site" --timeout 30
    sleep 2  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∫—Ä–∞—É–ª–∏–Ω–≥–∞–º–∏
done
```

### –ö—Ä–∞—É–ª–∏—Ç—å —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ —Ä–∞–∑–Ω—ã–µ —Ñ–∞–π–ª—ã
```bash
sites=("https://example.com" "https://wikipedia.org")
for site in "${sites[@]}"; do
    domain=$(echo "$site" | cut -d'/' -f3)
    ./crawler --url "$site" --output-dir "./data/$domain"
done
```

## ‚öñÔ∏è –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–º–µ—á–∞–Ω–∏—è

–ü–µ—Ä–µ–¥ –∫—Ä–∞—É–ª–∏–Ω–≥–æ–º –ª—é–±–æ–≥–æ —Å–∞–π—Ç–∞:
1. ‚úÖ –ü—Ä–æ—á–∏—Ç–∞–π Terms of Service —Å–∞–π—Ç–∞
2. ‚úÖ –ü—Ä–æ–≤–µ—Ä—å robots.txt —Ñ–∞–π–ª
3. ‚úÖ –£–±–µ–¥–∏—Å—å —á—Ç–æ –∫—Ä–∞—É–ª–∏–Ω–≥ —Ä–∞–∑—Ä–µ—à–µ–Ω
4. ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π User-Agent
5. ‚úÖ –ù–µ –ø–µ—Ä–µ–¥–µ–ª–∞–π —Å–µ—Ä–≤–µ—Ä (–∏—Å–ø–æ–ª—å–∑—É–π —Ä–∞–∑—É–º–Ω—ã–π timeout)
6. ‚úÖ –°–æ–±–ª—é–¥–∞–π –∞–≤—Ç–æ—Ä—Å–∫–∏–µ –ø—Ä–∞–≤–∞ –Ω–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ï—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã:
1. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏ - –æ–Ω–∏ –æ—á–µ–Ω—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã
2. –ü—Ä–æ—á–∏—Ç–∞–π LOGGING.md –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ª–æ–≥–æ–≤
3. –ü–æ—Å–º–æ—Ç—Ä–∏ –ø—Ä–∏–º–µ—Ä—ã –≤ examples.sh
4. –ü—Ä–æ–≤–µ—Ä—å config.json –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å

---

**–ü–æ–º–Ω–∏:** –í—Å–µ–≥–¥–∞ –∫—Ä–∞—É–ª–∏—Ä—É–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ! üôè
